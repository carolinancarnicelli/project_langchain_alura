# ğŸ“Š Projeto: Analisador Inteligente de Dados com LangChain, Groq e Streamlit

Este projeto implementa uma aplicaÃ§Ã£o interativa em **Streamlit** que permite:

* Carregar arquivos CSV grandes.
* Visualizar os dados.
* Fazer perguntas para um **agente inteligente baseado em LLM (Groq + LangChain)**.
* Gerar grÃ¡ficos automatizados com base em perguntas em linguagem natural.
* Criar um fluxo modular com ferramentas personalizadas (â€œtoolsâ€) para anÃ¡lise de dados.

O objetivo Ã© fornecer uma plataforma simples, rÃ¡pida e eficiente para automatizar anÃ¡lises exploratÃ³rias e geraÃ§Ã£o de insights a partir de datasets tabulares.

---

# ğŸš€ Tecnologias Utilizadas

| Tecnologia                          | Uso                                                                  |
| ----------------------------------- | -------------------------------------------------------------------- |
| **LangChain 0.3+ (versÃ£o moderna)** | CriaÃ§Ã£o das ferramentas, agentes e cadeia de raciocÃ­nio.             |
| **Groq API (LLaMA 3.x)**            | Modelo LLM ultrarrÃ¡pido para consultas e geraÃ§Ã£o de cÃ³digo/insights. |
| **Streamlit 1.44+**                 | Interface web interativa.                                            |
| **Pandas 2.2+**                     | Processamento de dados tabulares.                                    |
| **Matplotlib / Seaborn**            | CriaÃ§Ã£o de grÃ¡ficos automatizados.                                   |
| **python-dotenv**                   | Controle de variÃ¡veis de ambiente e seguranÃ§a.                       |

---

# ğŸ“ Estrutura do Projeto

```
/
â”œâ”€â”€ app.py                     # AplicaÃ§Ã£o Streamlit principal
â”œâ”€â”€ agent_tools.py             # Ferramentas personalizadas para o agente
â”œâ”€â”€ agent_setup.py             # ConfiguraÃ§Ã£o do LLM, agente e execuÃ§Ã£o
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ dados/                     # Arquivos CSV enviados pelo usuÃ¡rio (em runtime)
â””â”€â”€ README.md                  # Este arquivo
```

---

# âš™ï¸ Funcionalidades

### âœ”ï¸ Upload de arquivo CSV

O usuÃ¡rio faz upload de um arquivo `.csv`, que Ã© automaticamente lido com tratamento de encoding e separadores.

### âœ”ï¸ PrÃ©-visualizaÃ§Ã£o automÃ¡tica dos dados

O app exibe:

* NÃºmero de linhas e colunas
* CabeÃ§alho
* Preview das primeiras linhas

### âœ”ï¸ Agente inteligente para anÃ¡lise

O usuÃ¡rio pode escrever perguntas, como:

* *â€œQual Ã© a mÃ©dia do tempo_entrega por clima?â€*
* *â€œMostre a contagem de entregas por cidade.â€*

O LLM interpreta a pergunta, gera cÃ³digo **pandas** seguro e executa automaticamente no backend.

### âœ”ï¸ GeraÃ§Ã£o automÃ¡tica de grÃ¡ficos

Perguntas como:

* *â€œCrie um grÃ¡fico de barras com a mÃ©dia do tempo_entrega por clima.â€*

resultam em um grÃ¡fico renderizado diretamente no Streamlit.

### âœ”ï¸ Ferramentas personalizadas (LangChain Tools)

Criamos ferramentas que o agente pode usar:

* `InformaÃ§Ãµes DataFrame`
* `Resumo EstatÃ­stico`
* `Gerar GrÃ¡fico`
* `Executar CÃ³digo Python` (sandbox controlado)

### âœ”ï¸ OtimizaÃ§Ã£o de tokens para Groq

* Limpeza do contexto
* LimitaÃ§Ã£o de histÃ³rico
* Uso de modelos menores quando possÃ­vel
* ExecuÃ§Ã£o real de cÃ³digo para evitar respostas verbosas

---

# ğŸ”§ InstalaÃ§Ã£o

### 1. Clonar este repositÃ³rio

```bash
git clone https://github.com/<seu-usuario>/<seu-repositorio>.git
cd <seu-repositorio>
```

### 2. Criar ambiente virtual

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

### 3. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Criar arquivo `.env`

```ini
GROQ_API_KEY="sua-chave-groq"
```

---

# â–¶ï¸ ExecuÃ§Ã£o Local

```bash
streamlit run app.py
```

Abra no navegador:
`http://localhost:8501`

---

# ğŸ“¦ Deploy na Streamlit Cloud

1. Subir o repo para o GitHub
2. Acessar: [https://share.streamlit.io](https://share.streamlit.io)
3. Selecionar o repositÃ³rio
4. Adicionar variÃ¡vel de ambiente:

```
GROQ_API_KEY
```

### Cuidados importantes:

* A Streamlit Cloud tem **limites de memÃ³ria** â†’ trate arquivos CSV pesados.
* Evite enviar o DataFrame completo ao LLM â†’ use *row sampling* (ex. 200 primeiras linhas).
* Evite loops infinitos no agente â†’ configure limites de interaÃ§Ã£o.

---

# âš ï¸ Problemas conhecidos e SoluÃ§Ãµes

### 1. â— â€œAgent stopped due to iteration limitâ€

O agente gerou um loop.
**SoluÃ§Ã£o:** reduzir nÃºmero de steps, limitar ferramentas, revisar prompts.

### 2. â— â€œRequest too large â€” TPM limit exceededâ€

Pedido grande demais para o Groq.
**SoluÃ§Ã£o:**

* reduzir tamanho do DataFrame enviado ao prompt
* remover histÃ³rico
* usar modelo *llama-3.1-8b-instant*

### 3. â— GrÃ¡ficos nÃ£o aparecem no Streamlit

Ocorria quando o LLM gerava cÃ³digo com `plt.show()`.
**SoluÃ§Ã£o atual:** cÃ³digo modernizado usa `st.pyplot(fig)`.

---

# ğŸ§  Arquitetura do Agente

O projeto segue um fluxo moderno do LangChain 0.3+:

1. LLM Groq configurado
2. Tools registradas
3. AgentExecutor criado em modo *tool-calling*
4. Pergunta â†’ LLM decide qual tool usar
5. Se gerar cÃ³digo â†’ sandbox executa
6. Resultado retornado ao Streamlit

Isso garante seguranÃ§a, controle e menor consumo de tokens. âš¡

---

# ğŸ“š Exemplo de Pergunta

### Pergunta:

> Qual Ã© a mÃ©dia do tempo de entrega por tipo de clima?

### Processo:

1. LLM interpreta a intenÃ§Ã£o
2. Gera cÃ³digo Pandas:

```python
df.groupby("clima")["tempo_entrega"].mean()
```

3. Executa
4. Retorna o DataFrame formatado
5. Pode opcionalmente gerar grÃ¡fico

---

# ğŸŒŸ Melhorias Futuras

* Adicionar cache inteligente com `st.cache_data`
* Suporte a mÃºltiplos arquivos simultÃ¢neos
* ExportaÃ§Ã£o automÃ¡tica de relatÃ³rios PDF/Excel
* HistÃ³rico de consultas
* Modo batch para pipelines de ETL

---

# ğŸ“œ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT â€“ livre para uso e modificaÃ§Ã£o.
